{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100  # number of points in timeseries\n",
    "num_samples = 2  # number of time series\n",
    "num_features = 1  # features measured per time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "ts_sample = np.random.randn(num_steps, num_features)  # a single sample from ts\n",
    "# ts_samples = np.random.randn(num_samples, num_steps, num_features)  # multiple ts samples \n",
    "\n",
    "ts_label = np.random.choice([0, 1], p=[0.95, 0.05], size=num_steps)  # 1 is the anomaly\n",
    "ts_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to predict if an anomaly occured at time step `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time series index starting at 90 and ending at 100 has label 0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 10  # number of past consecutive readings in a window -> encodes into q (latent space dim)\n",
    "end_time = 100\n",
    "start_time = end_time - p \n",
    "f\"time series index starting at {start_time} and ending at {end_time} has label {ts_label[end_time-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def get_window(x, window_size=10, end_step=100, indices=None, return_indices=True):\n",
    "    \"\"\"\n",
    "    Returns a window from x of window_size, ending in end_step.\n",
    "\n",
    "    If actual indices are passed, a window corresponding to that will be taken.\n",
    "    \"\"\"\n",
    "    start_step = end_step-window_size\n",
    "    indices = np.asarray(range(0, len(x))) if indices is None else indices\n",
    "    if return_indices:\n",
    "        return indices[start_step:end_step]\n",
    "    else:\n",
    "        return x[indices[start_step:end_step], :]  # x of shape (num_features, feature_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window(ts_sample, window_size=p, end_step=num_steps, return_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be multiple sequences ending at time t based the `p` we set. \n",
    "\n",
    "Maximum possible rolling windows, for all possible `end_time`: `num_steps-p`\n",
    "\n",
    "VAEs will be trained on such a \"rolling window\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_windows = num_steps-p\n",
    "max_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window(ts_sample, window_size=p, end_step=10, return_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM is trained on the embeddings generated by the VAE encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10  # non overlapping window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `k=1`, then the windows will overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time series index starting at 0 and ending at 9 has label 1\n",
      "time series index starting at 10 and ending at 19 has label 0\n",
      "time series index starting at 20 and ending at 29 has label 0\n",
      "time series index starting at 30 and ending at 39 has label 0\n",
      "time series index starting at 40 and ending at 49 has label 0\n",
      "time series index starting at 50 and ending at 59 has label 0\n",
      "time series index starting at 60 and ending at 69 has label 0\n",
      "time series index starting at 70 and ending at 79 has label 0\n",
      "time series index starting at 80 and ending at 89 has label 0\n"
     ]
    }
   ],
   "source": [
    "for time in range(10, 100, k):\n",
    "    # assuming we just want windows at every 10th step\n",
    "    indices = get_window(ts_sample, window_size=p, end_step=time)\n",
    "    start_time = indices[0]\n",
    "    print(f\"time series index starting at {start_time} and ending at {indices[-1]} has label {ts_label[time]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All of these windows of varying lengths can be embdedded into the same dimension `q`. \n",
    "\n",
    "- The LSTM model acts on these embeddings, but those embeddings should correspond to non-overlapping windows.\n",
    "\n",
    "> I guess, for each `end_time`, there can only be one such window.\n",
    "\n",
    "- After the VAE model has been optimised, we use the encoder from the trained VAE model to estimate the embedding sequences $E_t$.\n",
    "\n",
    "- To train the LSTM model, we have the LSTM model take the first `k − 1` embeddings in a sequence $E_t$ and predict the next `k − 1` embeddings.\n",
    "\n",
    "- (most important) All the model parameters for both VAE and LSTM units are optimised without anomaly labels\n",
    "- \n",
    "- Also need to define a threshold $\\theta$ on the score function $d_t$, above which we will flag an anomaly alert $y_t = 1$ at the current $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
