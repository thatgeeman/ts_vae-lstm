{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "from ts_vae_lstm.concepts import get_window\n",
    "from scipy import signal\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a VAE with no anomalies in the time series.\n",
    "\n",
    "```--> Anomalies occur at:\n",
    "  timestamp #0: 2014-11-01 19:00:00\n",
    "  timestamp #1: 2014-11-27 15:30:00\n",
    "  timestamp #2: 2014-12-25 15:00:00\n",
    "  timestamp #3: 2015-01-01 01:00:00\n",
    "  timestamp #4: 2015-01-27 00:00:00\n",
    "\n",
    "Original csv file contains (10320,) timestamps.\n",
    "Processed time series contain (10320,) readings.\n",
    "Anomaly indices are [5943, 7184, 8527, 8835, 10081]\n",
    "\n",
    "Training set mean is 14855.115757575757\n",
    "Training set std is 6556.134705703313\n",
    "Anomaly indices in the test set are [2643 3884 5227 5535 6781]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "data = np.load(\"../sample_data/nyc_taxi.npz\")\n",
    "for k in data.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"t_unit\"]  # 1 hour is 2 steps, 24hrs is 48 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"training\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "df = pd.DataFrame(data[\"training\"], index=data[\"t_train\"], columns=[\"value\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "window_size = 48  # so that one window is one day\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"subset\": get_window(\n",
    "            df.values,\n",
    "            window_size=window_size,\n",
    "            end_step=end_step,\n",
    "            indices=list(df.index),\n",
    "            return_indices=False,\n",
    "        ),\n",
    "        \"end_step\": end_step,\n",
    "        \"start_step\": end_step - window_size,\n",
    "    }\n",
    "    for end_step in range(window_size, len(df))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of datapoints\n",
    "len(df) - window_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preseve 10% of the dataset from this for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "val_data_idxs = np.random.choice(\n",
    "    range(len(data)), size=int(0.1 * len(data)), replace=False\n",
    ")\n",
    "trn_data_idxs = [idx for idx in range(len(data)) if idx not in val_data_idxs]\n",
    "len(val_data_idxs), len(trn_data_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "val_data = [data[idx] for idx in val_data_idxs]\n",
    "trn_data = [data[idx] for idx in trn_data_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate stats over training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data[0][\"subset\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "n_features = trn_data[0][\"subset\"].shape[1]  # - 1\n",
    "n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "means = np.zeros((len(trn_data), n_features))  # ((len(trn_data), 4))\n",
    "stds = np.zeros((len(trn_data), n_features))  # ((len(trn_data), 4))\n",
    "slice_from = n_features - 1\n",
    "\"\"\"\n",
    "for i, _trn_data in enumerate(trn_data):\n",
    "    means[i] = (np.mean(_trn_data[\"subset\"][:, slice_from:], axis=0)).astype(np.float32)\n",
    "    stds[i] = (np.var(_trn_data[\"subset\"][:, slice_from:], axis=0) ** 0.5).astype(\n",
    "        np.float32\n",
    "    )\n",
    "\"\"\"\n",
    "means = means.mean(0)\n",
    "stds = stds.mean(0)\n",
    "\n",
    "means, stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only first feature is numeric, so remove mean and std from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means[slice_from:] = 0\n",
    "stds[slice_from:] = 1\n",
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TSDataset(Dataset):\n",
    "    def __init__(self, data, mean, std):\n",
    "        self.data = data\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "        # ignore the timestamp column\n",
    "        x = self.data[idx][\"subset\"][:, slice_from:]  # 1024, 4\n",
    "        normed_X = ((x - self.mean) / (self.std + 1e-8)).astype(np.float32)\n",
    "        return torch.as_tensor(normed_X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "dset_trn = TSDataset(trn_data, mean=means, std=stds)\n",
    "dset_val = TSDataset(\n",
    "    val_data, mean=means, std=stds\n",
    ")  # use same stats from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_trn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "dl_trn = DataLoader(\n",
    "    dataset=dset_trn,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "    dataset=dset_val,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = next(iter(dl_trn))\n",
    "xs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units = 512\n",
    "kernel_size = (3, 1)\n",
    "stride = (2, 1)\n",
    "xs_c1 = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=num_hidden_units // 16,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs.unsqueeze(1))\n",
    "xs_c2 = nn.Conv2d(\n",
    "    in_channels=num_hidden_units // 16,\n",
    "    out_channels=num_hidden_units // 8,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c1)\n",
    "xs_c3 = nn.Conv2d(\n",
    "    in_channels=num_hidden_units // 8,\n",
    "    out_channels=num_hidden_units // 4,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c2)\n",
    "xs_c4 = nn.Conv2d(\n",
    "    in_channels=num_hidden_units // 4,\n",
    "    out_channels=num_hidden_units // 1,\n",
    "    kernel_size=(4, 1),\n",
    "    stride=stride,\n",
    ")(xs_c3)\n",
    "xs_c1.shape, xs_c2.shape, xs_c3.shape, xs_c4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_c4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# encoder\n",
    "# l_win to 24, the model would consider each 24-hour period as one sequence.\n",
    "# pad: if your array is [1, 2, 3] and you symmetrically pad it with 1 unit, the result would be [2, 1, 2, 3, 2].\n",
    "# xavier_initializer()\n",
    "# conv 1: num_hidden_units / 16\n",
    "# conv 2: num_hidden_units / 8\n",
    "# conv 3: num_hidden_units / 4\n",
    "# conv 4: num_hidden_units / 1, kernel = 4, 1\n",
    "# padding : same\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=20,\n",
    "        num_hidden_units=512,\n",
    "        kernel_size=(3, 1),\n",
    "        stride=(2, 1),\n",
    "        act=F.mish,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=num_hidden_units // 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=num_hidden_units // 16,\n",
    "            out_channels=num_hidden_units // 8,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=num_hidden_units // 8,\n",
    "            out_channels=num_hidden_units // 4,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=num_hidden_units // 4,\n",
    "            out_channels=num_hidden_units,\n",
    "            kernel_size=(4, 1),\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=num_hidden_units, out_features=num_hidden_units, bias=True\n",
    "        )\n",
    "        self.linear_mean = nn.Linear(\n",
    "            in_features=num_hidden_units, out_features=latent_dim, bias=True\n",
    "        )\n",
    "        self.linear_var = nn.Linear(\n",
    "            in_features=num_hidden_units, out_features=latent_dim, bias=True\n",
    "        )\n",
    "        self.act = act\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # 100, 1, 48, 1\n",
    "        x = self.act(self.conv1(x))  # 100, 32, 23, 1\n",
    "        x = self.act(self.conv2(x))  # 100, 64, 11, 1\n",
    "        x = self.act(self.conv3(x))  # 100, 128, 5, 1\n",
    "        x = self.act(self.conv4(x))  # 100, 512, 1, 1\n",
    "        x = self.flatten(x)  # 100, 512\n",
    "        x = self.act(self.linear(x))  # 100, 512\n",
    "        z_mean = self.linear_mean(x)\n",
    "        z_log_var = self.linear_var(x)\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0)\n",
    "            elif isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mean, emb_var = Encoder(latent_dim=20)(xs)\n",
    "emb_mean.shape, emb_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mean.mean(), emb_var.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class StochasticSampler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sampler = torch.distributions.Normal(loc=0, scale=1)\n",
    "\n",
    "    def forward(self, z_mean, z_log_var):\n",
    "        # z_mean and z_log_var are mean and log-var estimates of the latent space\n",
    "        # under the assumption that the latent space is a gaussian normal\n",
    "        device = z_mean.device\n",
    "        eps = self.sampler.sample(z_mean.shape).squeeze().to(device)\n",
    "        # print(eps.shape, z_log_var.shape, z_mean.shape)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = StochasticSampler()\n",
    "emb = sampler(emb_mean, emb_var)\n",
    "emb.shape, emb.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3, 1)\n",
    "stride = 1\n",
    "xs_c1 = nn.Linear(in_features=20, out_features=num_hidden_units, bias=True)(emb)\n",
    "xs_c1 = xs_c1[:, :, None, None]\n",
    "xs_c2 = nn.ConvTranspose2d(\n",
    "    in_channels=num_hidden_units,\n",
    "    out_channels=num_hidden_units // 4,\n",
    "    kernel_size=(4, 1),\n",
    "    stride=stride,\n",
    ")(xs_c1)\n",
    "xs_c3 = nn.ConvTranspose2d(\n",
    "    in_channels=num_hidden_units // 4,\n",
    "    out_channels=num_hidden_units // 8,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c2)\n",
    "xs_c4 = nn.ConvTranspose2d(\n",
    "    in_channels=num_hidden_units // 8,\n",
    "    out_channels=num_hidden_units // 16,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c3)\n",
    "xs_c5 = nn.ConvTranspose2d(\n",
    "    in_channels=num_hidden_units // 16,\n",
    "    out_channels=num_hidden_units // 32,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c4)\n",
    "xs_c6 = nn.ConvTranspose2d(\n",
    "    in_channels=num_hidden_units // 32,\n",
    "    out_channels=num_hidden_units // 64,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    ")(xs_c5)\n",
    "xs_c6 = nn.Flatten()(xs_c6)\n",
    "xs_c7 = nn.Linear(in_features=96, out_features=48, bias=True)(xs_c6)\n",
    "xs_c1.shape, xs_c2.shape, xs_c3.shape, xs_c4.shape, xs_c5.shape, xs_c6.shape, xs_c7.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# l_win to 24, the model would consider each 24-hour period as one sequence.\n",
    "# pad: if your array is [1, 2, 3] and you symmetrically pad it with 1 unit, the result would be [2, 1, 2, 3, 2].\n",
    "# xavier_initializer()\n",
    "# dense 1: num_hidden_units\n",
    "# reshape: (bs, 1, 1, num_hidden_units)  -> this is tensorflow notation, channel at end so actually (bs, num_hidden_units, 1, 1)\n",
    "\n",
    "# conv 2: num_hidden_units, kernel = 1\n",
    "# reshape: (bs, 4, 1, num_hidden_units / 4)\n",
    "\n",
    "# conv 3: num_hidden_units / 4, kernel = 3, 1, stride = 1\n",
    "# permute depth to spatial tf\n",
    "# reshape: (bs, 8, 1, num_hidden_units / 8),\n",
    "\n",
    "# conv 4: num_hidden_units / 8,  kernel = 3, 1, stride = 1\n",
    "# permute depth to spatial tf\n",
    "# reshape: (bs, 16, 1, num_hidden_units / 16)\n",
    "\n",
    "# conv 5: num_hidden_units / 16, kernel = 3, 1, stride = 1\n",
    "# permute depth to spatial tf\n",
    "# reshape: (bs, num_hidden_units /16, 1,  16)\n",
    "\n",
    "# conv 6: num_channel, kernel = 9, 1, stride = 1\n",
    "# reshape: (bs, l_win, num_channel)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_shape,\n",
    "        latent_dim=20,\n",
    "        num_hidden_units=512,\n",
    "        kernel_size=(3, 1),\n",
    "        stride=1,\n",
    "        act=F.mish,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_shape = output_shape\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=latent_dim, out_features=num_hidden_units, bias=True\n",
    "        )\n",
    "        self.dconv1 = nn.ConvTranspose2d(\n",
    "            in_channels=num_hidden_units,\n",
    "            out_channels=num_hidden_units // 4,\n",
    "            kernel_size=(4, 1),\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.dconv2 = nn.ConvTranspose2d(\n",
    "            in_channels=num_hidden_units // 4,\n",
    "            out_channels=num_hidden_units // 8,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.dconv3 = nn.ConvTranspose2d(\n",
    "            in_channels=num_hidden_units // 8,\n",
    "            out_channels=num_hidden_units // 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.dconv4 = nn.ConvTranspose2d(\n",
    "            in_channels=num_hidden_units // 16,\n",
    "            out_channels=num_hidden_units // 32,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.dconv5 = nn.ConvTranspose2d(\n",
    "            in_channels=num_hidden_units // 32,\n",
    "            out_channels=num_hidden_units // 64,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_out = nn.Linear(\n",
    "            in_features=96, out_features=math.prod(output_shape), bias=True\n",
    "        )\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x[:, :, None, None]\n",
    "        x = self.act(self.dconv1(x))\n",
    "        x = self.act(self.dconv2(x))\n",
    "        x = self.act(self.dconv3(x))\n",
    "        x = self.act(self.dconv4(x))\n",
    "        x = self.act(self.dconv5(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.act(self.linear_out(x))\n",
    "        return self.reshape_to_output(x)\n",
    "\n",
    "    def reshape_to_output(self, x):\n",
    "        bs = x.shape[0]\n",
    "        return x.reshape(bs, *self.output_shape)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0)\n",
    "            elif isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder(output_shape=(window_size, n_features))(emb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim=20, act=F.leaky_relu):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, act=act)\n",
    "        self.decoder = Decoder(output_shape=input_shape, latent_dim=latent_dim, act=act)\n",
    "        self.latent_sampler = StochasticSampler()\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_log_var = self.encoder(x)\n",
    "        z = self.latent_sampler(z_mean, z_log_var)\n",
    "        out = self.decoder(z)\n",
    "        # loss to enforce all possible values are sampled from latent space\n",
    "        # should be of the size of the batch\n",
    "        loss_kl = -0.5 * torch.sum(\n",
    "            1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=-1\n",
    "        )\n",
    "        return out, loss_kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_pred, loss_kl = VAE(latent_dim=128, input_shape=(window_size, n_features))(xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_pred.shape, loss_kl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def calculate_smape(predicted, actual):\n",
    "    with torch.no_grad():\n",
    "        absolute_percentage_errors = (\n",
    "            torch.abs(predicted - actual) / (torch.abs(predicted) + torch.abs(actual))\n",
    "        ) * 100\n",
    "        return absolute_percentage_errors.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def loss_func(inputs, targets, loss_kl, beta=0.5):\n",
    "    # targets = torch.where(targets >= 0, 1., 0.)\n",
    "    bs = inputs.shape[0]\n",
    "    # loss_kl = loss_kl.unsqueeze(-1)  # add loss_kl per time step.\n",
    "    loss_reconstruct_numerical = F.huber_loss(\n",
    "        inputs,\n",
    "        targets,\n",
    "        delta=3,\n",
    "        reduction=\"none\",\n",
    "    ).sum((-1, -2))\n",
    "    # loss only for the signal\n",
    "    # loss_reconstruct = calculate_smape(inputs, targets).mean((1, 2))\n",
    "    # should be of the size of the batch to add losses correctly\n",
    "    # loss_kl of shape bs,\n",
    "    # loss_reconstruct of shape bs,\n",
    "    # print(loss_reconstruct_numerical.shape, loss_kl.shape)\n",
    "    \"\"\"print(\n",
    "        loss_kl.shape,\n",
    "        loss_reconstruct_numerical,\n",
    "        # loss_reconstruct_categorical.shape,\n",
    "    )\"\"\"\n",
    "    return torch.mean(loss_reconstruct_numerical + loss_kl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(xs_pred.to(\"cpu\"), xs.to(\"cpu\"), loss_kl.to(\"cpu\"), beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_similarity(inputs, targets):\n",
    "    func = F.mse_loss\n",
    "    with torch.no_grad():\n",
    "        loss_num = func(inputs.flatten(), targets.flatten())\n",
    "        return loss_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity(\n",
    "    xs_pred.to(\"cpu\"),\n",
    "    xs.to(\"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_smape(\n",
    "    xs_pred.to(\"cpu\"),\n",
    "    xs.to(\"cpu\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def validate_epoch(dls, criterion, scorer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_score = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, xs in enumerate(dls):\n",
    "            # move to device\n",
    "            xs = xs.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            xs_gen, loss_kl = model(xs)\n",
    "\n",
    "            loss = criterion(xs_gen, targets=xs, loss_kl=loss_kl)\n",
    "            # print(loss - loss_kl, loss_kl)\n",
    "            # calc score\n",
    "            score = scorer(xs_gen, xs)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_score += score.item()\n",
    "    return running_loss, running_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from fastcore.xtras import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "train_dataloader = dl_trn\n",
    "valid_dataloader = dl_val\n",
    "\n",
    "activation = partial(F.hardtanh, min_val=-3, max_val=3)\n",
    "model = VAE(latent_dim=128, input_shape=(window_size, n_features), act=activation).to(\n",
    "    device\n",
    ")  # to make visualization easier, 2 latent dims\n",
    "\n",
    "learning_rate = 1e-3\n",
    "criterion = loss_func\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "scorer = calculate_smape\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "print_every = len(train_dataloader)\n",
    "\n",
    "# Define LR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.9, patience=10, min_lr=1e-8, verbose=True\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_score = 0.0\n",
    "    if not train:\n",
    "        break\n",
    "    for batch_idx, xs in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # move to device\n",
    "        xs = xs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        xs_gen, loss_kl = model(xs)\n",
    "\n",
    "        loss = criterion(xs_gen, targets=xs, loss_kl=loss_kl)\n",
    "        # calc score\n",
    "        score = scorer(xs_gen, xs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_score += score.item()\n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            val_loss, val_score = validate_epoch(valid_dataloader, criterion, scorer)\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_dataloader)}], Trn Loss: {(running_loss / print_every):.6f}, Trn Score: {(running_score / print_every):.6f}, Val Loss: {(val_loss/len(valid_dataloader)):.6f}, Val Score: {(val_score/len(valid_dataloader)):.6f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_score = 0.0\n",
    "    # Step the LR scheduler\n",
    "    scheduler.step(val_loss)  # min the running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"../models/vae_{num_epochs}.pth\")\n",
    "f\"../models/vae_{num_epochs}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"../models/vae_{num_epochs}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xs_val = next(iter(dl_val))\n",
    "    xs_val_gen, loss_kl = model(xs_val.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(batch_size // 3):\n",
    "    plt.subplot(5, 2, idx + 1)\n",
    "    idx_feature = 0\n",
    "    decoded_example, actual_example = (\n",
    "        xs_val_gen[idx].detach().cpu(),\n",
    "        xs_val[idx].detach().cpu(),\n",
    "    )\n",
    "    sns.lineplot(actual_example[:, idx_feature].numpy(), alpha=0.5)  # , label=\"true\",\n",
    "    sns.lineplot(decoded_example[:, idx_feature].numpy())  # , label=\"vae\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xs_val = next(iter(dl_val))\n",
    "    emb_mean_val, emb_std_val = model.encoder(xs_val.to(device))\n",
    "    emb_val = model.latent_sampler(emb_mean_val, emb_std_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=emb_val[:, 0].cpu(), y=emb_val[:, 1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae-lstm-kernel",
   "language": "python",
   "name": "vae-lstm-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
